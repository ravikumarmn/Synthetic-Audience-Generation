#!/usr/bin/env python3
"""
Synthetic Audience Generator MVP
Single-file implementation using LangChain + LangGraph + Gemini Flash 2.5

This MVP generates synthetic audience profiles with exact demographic distribution
matching while using LLM only for behavioral content generation.
"""

import json
import os
import re
import warnings
import time
import random
from typing import Dict, List, TypedDict, Optional, Tuple, Any
from dataclasses import dataclass
import logging

# Core dependencies
from pydantic import BaseModel, Field, validator
from dotenv import load_dotenv
from tqdm import tqdm
import click

# LangChain and LangGraph
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ============================================================================
# CORE DATA MODELS
# ============================================================================


class FilterDetails(BaseModel):
    """Input filter details from JSON request."""

    user_req_responses: int = Field(
        ..., gt=0, description="Number of responses required"
    )
    age_filter: Dict[str, int] = Field(..., description="Age bounds")
    age_proportions: Dict[str, int] = Field(..., description="Age group proportions")
    gender_filter: List[str] = Field(..., description="Allowed genders")
    gender_proportions: Dict[str, int] = Field(..., description="Gender proportions")
    ethnicity_filter: List[str] = Field(..., description="Allowed ethnicities")
    ethnicity_proportions: Dict[str, int] = Field(
        ..., description="Ethnicity proportions"
    )
    age_filter_complete: bool = Field(default=True)
    ethnicity_filter_complete: bool = Field(default=True)

    @validator("age_proportions", "gender_proportions", "ethnicity_proportions")
    def validate_proportions_sum_to_100(cls, v):
        """Ensure proportions sum to 100."""
        total = sum(v.values())
        if total != 100:
            raise ValueError(f"Proportions must sum to 100, got {total}")
        return v


class InputPersona(BaseModel):
    """Input persona from JSON request."""

    id: int
    generatedTitle: str
    personaName: str
    age: int
    location: str
    ethnicity: str
    gender: str
    personaType: str
    about: str
    goalsAndMotivations: List[str]
    frustrations: List[str]
    needState: str
    occasions: str
    image: Optional[str] = None
    userId: Optional[int] = None
    createdAt: Optional[str] = None
    requestParams: Optional[Dict] = None


class RequestData(BaseModel):
    """Complete request data structure."""

    request: List[Dict[str, Any]]

    def get_filter_details(self) -> FilterDetails:
        """Extract filter details from request."""
        return FilterDetails(**self.request[0]["filter_details"])

    def get_personas(self) -> List[InputPersona]:
        """Extract personas from request."""
        return [InputPersona(**persona) for persona in self.request[0]["personas"]]


class DemographicAssignment(BaseModel):
    """Demographic assignment for a single profile."""

    age_bucket: str
    gender: str
    ethnicity: str
    profile_index: int


class BehavioralContent(BaseModel):
    """Generated behavioral content from LLM."""

    about: str = Field(..., description="About section")
    goalsAndMotivations: List[str] = Field(..., description="Goals and motivations")
    frustrations: List[str] = Field(..., description="Frustrations")
    needState: str = Field(..., description="Need state")
    occasions: str = Field(..., description="Occasions")


class SyntheticProfile(BaseModel):
    """Complete synthetic audience profile."""

    # Demographics (assigned by Python)
    age_bucket: str
    gender: str
    ethnicity: str

    # Behavioral content (generated by LLM)
    about: str
    goalsAndMotivations: List[str]
    frustrations: List[str]
    needState: str
    occasions: str

    # Metadata
    profile_id: int


class ProcessingTemplates(BaseModel):
    """Cleaned templates for LLM generation."""

    about_templates: List[str]
    goals_templates: List[str]
    frustrations_templates: List[str]
    need_state_templates: List[str]
    occasions_templates: List[str]


# ============================================================================
# LANGGRAPH STATE MANAGEMENT
# ============================================================================


class SyntheticAudienceState(TypedDict):
    """State management for LangGraph workflow."""

    # Input data
    filter_details: FilterDetails
    input_personas: List[InputPersona]

    # Processing data
    demographic_schedule: List[DemographicAssignment]
    processing_templates: ProcessingTemplates

    # Generation data
    current_profile_index: int
    current_demographic: Optional[DemographicAssignment]
    generated_content: Optional[BehavioralContent]

    # Output data
    completed_profiles: List[SyntheticProfile]

    # Metadata
    processing_errors: List[str]
    generation_stats: Dict[str, Any]


# ============================================================================
# DISTRIBUTION CALCULATION ENGINE
# ============================================================================


class DistributionCalculator:
    """Handles exact demographic distribution calculations."""

    @staticmethod
    def calculate_gender_distribution(
        total: int, proportions: Dict[str, int]
    ) -> Dict[str, int]:
        """Calculate exact gender distribution with rounding adjustment."""
        logger.info(f"Calculating gender distribution for {total} profiles")

        # Calculate base allocations
        allocations = {}
        remainders = {}

        for gender, percentage in proportions.items():
            exact_value = (percentage / 100.0) * total
            allocations[gender] = int(exact_value)
            remainders[gender] = exact_value - allocations[gender]

        # Distribute remaining profiles using largest remainder method
        total_allocated = sum(allocations.values())
        remaining = total - total_allocated

        if remaining > 0:
            # Sort by remainder descending
            sorted_remainders = sorted(
                remainders.items(), key=lambda x: x[1], reverse=True
            )
            for i in range(remaining):
                gender = sorted_remainders[i][0]
                allocations[gender] += 1

        logger.info(f"Gender distribution: {allocations}")
        return allocations

    @staticmethod
    def calculate_age_distribution(
        gender_dist: Dict[str, int], age_props: Dict[str, int]
    ) -> Dict[str, Dict[str, int]]:
        """Calculate age distribution within each gender group."""
        logger.info("Calculating age distribution per gender")

        result = {}
        for gender, gender_count in gender_dist.items():
            if gender_count == 0:
                result[gender] = {age_bucket: 0 for age_bucket in age_props.keys()}
                continue

            age_allocations = {}
            age_remainders = {}

            for age_bucket, percentage in age_props.items():
                exact_value = (percentage / 100.0) * gender_count
                age_allocations[age_bucket] = int(exact_value)
                age_remainders[age_bucket] = exact_value - age_allocations[age_bucket]

            # Distribute remaining using largest remainder method
            total_allocated = sum(age_allocations.values())
            remaining = gender_count - total_allocated

            if remaining > 0:
                sorted_remainders = sorted(
                    age_remainders.items(), key=lambda x: x[1], reverse=True
                )
                for i in range(remaining):
                    age_bucket = sorted_remainders[i][0]
                    age_allocations[age_bucket] += 1

            result[gender] = age_allocations

        logger.info(f"Age distribution: {result}")
        return result

    @staticmethod
    def calculate_ethnicity_distribution(
        age_gender_dist: Dict[str, Dict[str, int]], ethnicity_props: Dict[str, int]
    ) -> Dict[str, Dict[str, Dict[str, int]]]:
        """Calculate ethnicity distribution within each age-gender combination."""
        logger.info("Calculating ethnicity distribution per age-gender combination")

        result = {}
        for gender, age_dist in age_gender_dist.items():
            result[gender] = {}
            for age_bucket, age_count in age_dist.items():
                if age_count == 0:
                    result[gender][age_bucket] = {
                        ethnicity: 0 for ethnicity in ethnicity_props.keys()
                    }
                    continue

                ethnicity_allocations = {}
                ethnicity_remainders = {}

                for ethnicity, percentage in ethnicity_props.items():
                    exact_value = (percentage / 100.0) * age_count
                    ethnicity_allocations[ethnicity] = int(exact_value)
                    ethnicity_remainders[ethnicity] = (
                        exact_value - ethnicity_allocations[ethnicity]
                    )

                # Distribute remaining using largest remainder method
                total_allocated = sum(ethnicity_allocations.values())
                remaining = age_count - total_allocated

                if remaining > 0:
                    sorted_remainders = sorted(
                        ethnicity_remainders.items(), key=lambda x: x[1], reverse=True
                    )
                    for i in range(remaining):
                        ethnicity = sorted_remainders[i][0]
                        ethnicity_allocations[ethnicity] += 1

                result[gender][age_bucket] = ethnicity_allocations

        return result

    @staticmethod
    def generate_demographic_schedule(
        total: int,
        gender_props: Dict[str, int],
        age_props: Dict[str, int],
        ethnicity_props: Dict[str, int],
    ) -> List[DemographicAssignment]:
        """Generate complete demographic assignment schedule."""
        logger.info(f"Generating demographic schedule for {total} profiles")

        # Calculate distributions
        gender_dist = DistributionCalculator.calculate_gender_distribution(
            total, gender_props
        )
        age_gender_dist = DistributionCalculator.calculate_age_distribution(
            gender_dist, age_props
        )
        ethnicity_dist = DistributionCalculator.calculate_ethnicity_distribution(
            age_gender_dist, ethnicity_props
        )

        # Generate assignment schedule
        schedule = []
        profile_index = 0

        for gender in gender_dist.keys():
            for age_bucket in age_props.keys():
                for ethnicity in ethnicity_props.keys():
                    count = ethnicity_dist[gender][age_bucket][ethnicity]
                    for _ in range(count):
                        assignment = DemographicAssignment(
                            age_bucket=age_bucket,
                            gender=gender,
                            ethnicity=ethnicity,
                            profile_index=profile_index,
                        )
                        schedule.append(assignment)
                        profile_index += 1

        # Shuffle to randomize order
        random.shuffle(schedule)

        logger.info(f"Generated schedule with {len(schedule)} assignments")
        return schedule


# ============================================================================
# PERSONA CONTENT PROCESSOR
# ============================================================================


class PersonaProcessor:
    """Processes input personas to extract clean behavioral templates."""

    # Demographic content patterns to remove
    DEMOGRAPHIC_PATTERNS = [
        r"\b\d{1,2}[-\s]year[-\s]old\b",
        r"\bage\s+\d{1,2}\b",
        r"\b\d{1,2}\s+years?\s+old\b",
        r"\bmale\b|\bfemale\b",
        r"\bman\b|\bwoman\b|\bguy\b|\bgirl\b",
        r"\bhe\b|\bhis\b|\bhim\b|\bshe\b|\bher\b|\bhers\b",
        r"\bgender\b|\bsex\b",
        r"\bethnicity\b|\brace\b|\bnationality\b",
        r"\bwhite\b|\bblack\b|\basian\b|\bhispanic\b|\blatino\b|\blatina\b",
        r"\bcaucasian\b|\bafrican\b|\bamerican\b|\bindian\b|\bchinese\b|\bjapanese\b",
        r"\bmumbai\b|\bdelhi\b|\bbangalore\b|\bchennai\b|\bkolkata\b|\bhyderabad\b",
        r"\bindia\b|\bindian\b|\bhindi\b|\btamil\b|\btelugu\b|\bbengali\b",
        r"\brupees?\b|\b₹\b|\brs\.?\b|\binr\b",
        r"\bbandra\b|\bandheri\b|\bpowai\b|\bgoregaon\b|\bthane\b|\bnavi\s+mumbai\b",
    ]

    @staticmethod
    def clean_demographic_content(text: str) -> str:
        """Remove demographic references from text content."""
        cleaned_text = text

        for pattern in PersonaProcessor.DEMOGRAPHIC_PATTERNS:
            cleaned_text = re.sub(
                pattern, "[CONTENT]", cleaned_text, flags=re.IGNORECASE
            )

        # Clean up multiple spaces and placeholders
        cleaned_text = re.sub(r"\s+", " ", cleaned_text)
        cleaned_text = re.sub(r"\[CONTENT\]\s*", "", cleaned_text)
        cleaned_text = cleaned_text.strip()

        return cleaned_text

    @staticmethod
    def extract_behavioral_templates(
        personas: List[InputPersona],
    ) -> ProcessingTemplates:
        """Extract clean behavioral templates from personas."""
        logger.info(f"Extracting templates from {len(personas)} personas")

        about_templates = []
        goals_templates = []
        frustrations_templates = []
        need_state_templates = []
        occasions_templates = []

        for persona in personas:
            # Clean and extract about content
            cleaned_about = PersonaProcessor.clean_demographic_content(persona.about)
            if len(cleaned_about) > 50:  # Minimum content length
                about_templates.append(cleaned_about)

            # Clean and extract goals
            for goal in persona.goalsAndMotivations:
                cleaned_goal = PersonaProcessor.clean_demographic_content(goal)
                if len(cleaned_goal) > 20:
                    goals_templates.append(cleaned_goal)

            # Clean and extract frustrations
            for frustration in persona.frustrations:
                cleaned_frustration = PersonaProcessor.clean_demographic_content(
                    frustration
                )
                if len(cleaned_frustration) > 20:
                    frustrations_templates.append(cleaned_frustration)

            # Clean need state and occasions
            cleaned_need_state = PersonaProcessor.clean_demographic_content(
                persona.needState
            )
            if len(cleaned_need_state) > 10:
                need_state_templates.append(cleaned_need_state)

            cleaned_occasions = PersonaProcessor.clean_demographic_content(
                persona.occasions
            )
            if len(cleaned_occasions) > 20:
                occasions_templates.append(cleaned_occasions)

        templates = ProcessingTemplates(
            about_templates=list(set(about_templates)),  # Remove duplicates
            goals_templates=list(set(goals_templates)),
            frustrations_templates=list(set(frustrations_templates)),
            need_state_templates=list(set(need_state_templates)),
            occasions_templates=list(set(occasions_templates)),
        )

        logger.info(
            f"Extracted {len(templates.about_templates)} about templates, "
            f"{len(templates.goals_templates)} goals templates, "
            f"{len(templates.frustrations_templates)} frustrations templates"
        )

        return templates


# ============================================================================
# LLM CONTENT GENERATOR
# ============================================================================


class LLMContentGenerator:
    """Handles LLM integration for behavioral content generation."""

    def __init__(self):
        """Initialize the LLM with configuration."""
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment variables")

        self.llm = ChatGoogleGenerativeAI(
            model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash"),
            temperature=float(os.getenv("GEMINI_TEMPERATURE", "0.7")),
            max_tokens=int(os.getenv("GEMINI_MAX_TOKENS", "1500")),
            google_api_key=api_key,
        )

        self.max_retries = int(os.getenv("MAX_RETRIES", "5"))

        # Define generation prompt template
        self.prompt_template = PromptTemplate(
            input_variables=[
                "about_examples",
                "goals_examples",
                "frustrations_examples",
                "need_state_examples",
                "occasions_examples",
            ],
            template=self._get_generation_prompt(),
        )

    def _get_generation_prompt(self) -> str:
        """Get the LLM generation prompt template."""
        return """You are a behavioral content generator for synthetic audience profiles. 

CRITICAL REQUIREMENTS:
1. Generate ONLY behavioral content - NO demographic information whatsoever
2. Use ONLY gender-neutral language - avoid ALL pronouns (he, she, his, her, him, them, they)
3. Use neutral terms like "this person", "the individual", "someone", or "content creator"
4. Focus purely on behaviors, motivations, attitudes, and preferences
5. Return ONLY valid JSON with the exact structure specified
6. Content must be unique and realistic but avoid copying examples directly

ABSOLUTELY PROHIBITED CONTENT:
- ANY pronouns: he, she, his, her, him, them, they, their
- Gender words: male, female, man, woman, guy, girl, person (use "individual" instead)
- Age references: young, old, 23-year-old, millennial, gen-z, boomer
- Ethnicity/race references: Indian, Asian, White, Black, Hispanic, Latino
- Location references: Mumbai, Delhi, specific cities/countries, urban, rural
- Physical descriptions of any kind
- Names or specific personal identifiers

LANGUAGE GUIDELINES:
- Instead of "he creates content" → "the individual creates content"
- Instead of "she is passionate" → "this content creator is passionate"
- Instead of "they want to" → "the goal is to"
- Instead of "his work" → "the work"
- Use passive voice when needed to avoid pronouns

EXAMPLES FOR INSPIRATION (DO NOT COPY DIRECTLY):

About Examples:
{about_examples}

Goals Examples:
{goals_examples}

Frustrations Examples:
{frustrations_examples}

Need State Examples:
{need_state_examples}

Occasions Examples:
{occasions_examples}

Generate unique behavioral content inspired by these examples but with your own variation.

REQUIRED JSON OUTPUT FORMAT:
{{
    "about": "A behavioral description focusing on interests, lifestyle, and personality traits using gender-neutral language",
    "goalsAndMotivations": [
        "First goal or motivation without pronouns",
        "Second goal or motivation without pronouns", 
        "Third goal or motivation without pronouns"
    ],
    "frustrations": [
        "First frustration or challenge without pronouns",
        "Second frustration or challenge without pronouns",
        "Third frustration or challenge without pronouns"
    ],
    "needState": "Current emotional or motivational state",
    "occasions": "When and how content engagement happens, using neutral language"
}}

REMEMBER: NO PRONOUNS OR DEMOGRAPHIC REFERENCES AT ALL. Use "the individual", "this content creator", "someone" instead.

Generate the JSON now:"""

    def generate_content(self, templates: ProcessingTemplates) -> BehavioralContent:
        """Generate behavioral content using LLM."""
        # Prepare examples for prompt
        about_examples = "\n".join(templates.about_templates[:3])
        goals_examples = "\n".join(templates.goals_templates[:5])
        frustrations_examples = "\n".join(templates.frustrations_templates[:5])
        need_state_examples = "\n".join(templates.need_state_templates[:3])
        occasions_examples = "\n".join(templates.occasions_templates[:3])

        # Generate prompt
        prompt = self.prompt_template.format(
            about_examples=about_examples,
            goals_examples=goals_examples,
            frustrations_examples=frustrations_examples,
            need_state_examples=need_state_examples,
            occasions_examples=occasions_examples,
        )

        # Generate with retry logic
        for attempt in range(self.max_retries):
            try:
                response = self.llm.invoke(prompt)
                content_text = response.content

                # Parse JSON response
                content_data = self._parse_llm_response(content_text)

                # Clean and validate content
                cleaned_content = self._clean_generated_content(content_data)
                if self._validate_content(cleaned_content):
                    return BehavioralContent(**cleaned_content)
                else:
                    logger.warning(
                        f"Content validation failed on attempt {attempt + 1}"
                    )

            except Exception as e:
                logger.warning(f"Generation attempt {attempt + 1} failed: {str(e)}")
                if attempt < self.max_retries - 1:
                    time.sleep(2**attempt + random.uniform(0, 1))

        raise Exception(
            f"Failed to generate valid content after {self.max_retries} attempts"
        )

    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """Parse LLM response to extract JSON."""
        try:
            # Try direct JSON parsing
            return json.loads(response_text)
        except json.JSONDecodeError:
            # Try to extract JSON from response
            json_match = re.search(r"\{.*\}", response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            raise ValueError("No valid JSON found in response")

    def _clean_generated_content(self, content_data: Dict[str, Any]) -> Dict[str, Any]:
        """Clean generated content to remove demographic references."""
        cleaned_data = content_data.copy()

        # Define replacement patterns
        replacements = {
            # Pronouns
            r"\bhe\b": "the individual",
            r"\bshe\b": "the individual",
            r"\bhis\b": "the",
            r"\bher\b": "the",
            r"\bhim\b": "the individual",
            r"\bthey\b": "individuals",
            r"\bthem\b": "individuals",
            r"\btheir\b": "the",
            # Gender terms
            r"\bman\b": "individual",
            r"\bwoman\b": "individual",
            r"\bguy\b": "individual",
            r"\bgirl\b": "individual",
            r"\bperson\b": "individual",
            # Age terms
            r"\byoung\b": "",
            r"\bold\b": "experienced",
            r"\bmillennial\b": "individual",
            r"\bgen-z\b": "individual",
            r"\bboomer\b": "individual",
        }

        # Clean all text fields
        for field in ["about", "needState", "occasions"]:
            if field in cleaned_data and isinstance(cleaned_data[field], str):
                text = cleaned_data[field]
                for pattern, replacement in replacements.items():
                    text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                # Clean up extra spaces
                text = re.sub(r"\s+", " ", text).strip()
                cleaned_data[field] = text

        # Clean list fields
        for field in ["goalsAndMotivations", "frustrations"]:
            if field in cleaned_data and isinstance(cleaned_data[field], list):
                cleaned_list = []
                for item in cleaned_data[field]:
                    if isinstance(item, str):
                        text = item
                        for pattern, replacement in replacements.items():
                            text = re.sub(
                                pattern, replacement, text, flags=re.IGNORECASE
                            )
                        # Clean up extra spaces
                        text = re.sub(r"\s+", " ", text).strip()
                        cleaned_list.append(text)
                    else:
                        cleaned_list.append(item)
                cleaned_data[field] = cleaned_list

        return cleaned_data

    def _validate_content(self, content_data: Dict[str, Any]) -> bool:
        """Validate generated content for demographic leakage."""
        # Check required fields
        required_fields = [
            "about",
            "goalsAndMotivations",
            "frustrations",
            "needState",
            "occasions",
        ]
        if not all(field in content_data for field in required_fields):
            return False

        # Check for demographic content
        all_text = json.dumps(content_data).lower()

        demographic_keywords = [
            # Gender pronouns and references
            "he",
            "she",
            "his",
            "her",
            "him",
            "them",
            "they",
            "their",
            "male",
            "female",
            "man",
            "woman",
            "guy",
            "girl",
            "person",
            # Age references
            "age",
            "year",
            "old",
            "young",
            "millennial",
            "gen-z",
            "genz",
            "boomer",
            # Ethnicity/race
            "ethnicity",
            "race",
            "white",
            "black",
            "asian",
            "hispanic",
            "latino",
            "latina",
            "caucasian",
            "african",
            "american",
            "indian",
            "chinese",
            "japanese",
            # Location references
            "mumbai",
            "delhi",
            "bangalore",
            "chennai",
            "kolkata",
            "hyderabad",
            "india",
            "urban",
            "rural",
            "city",
            "town",
            "village",
            # Currency/regional
            "rupee",
            "₹",
            "rs.",
            "inr",
        ]

        for keyword in demographic_keywords:
            # Use word boundaries to avoid false positives in compound words
            pattern = r"\b" + re.escape(keyword) + r"\b"
            if re.search(pattern, all_text, re.IGNORECASE):
                logger.warning(f"Demographic content detected: {keyword}")
                return False

        return True


# ============================================================================
# MAIN APPLICATION CLASS
# ============================================================================


class SyntheticAudienceGenerator:
    """Main application class orchestrating the generation process."""

    def __init__(self):
        """Initialize the generator."""
        self.llm_generator = LLMContentGenerator()
        logger.info("Synthetic Audience Generator initialized")

    def process_request(self, input_file: str, output_file: str) -> Dict[str, Any]:
        """Process a complete generation request."""
        logger.info(f"Processing request from {input_file}")

        # Load and validate input
        with open(input_file, "r") as f:
            raw_data = json.load(f)

        request_data = RequestData(**raw_data)
        filter_details = request_data.get_filter_details()
        input_personas = request_data.get_personas()

        logger.info(f"Loaded request for {filter_details.user_req_responses} profiles")

        # Generate demographic schedule
        demographic_schedule = DistributionCalculator.generate_demographic_schedule(
            filter_details.user_req_responses,
            filter_details.gender_proportions,
            filter_details.age_proportions,
            filter_details.ethnicity_proportions,
        )

        # Process personas to extract templates
        processing_templates = PersonaProcessor.extract_behavioral_templates(
            input_personas
        )

        # Generate profiles
        completed_profiles = []

        logger.info("Starting profile generation...")
        for i, demographic in enumerate(
            tqdm(demographic_schedule, desc="Generating profiles")
        ):
            try:
                # Generate behavioral content
                behavioral_content = self.llm_generator.generate_content(
                    processing_templates
                )

                # Create complete profile
                profile = SyntheticProfile(
                    age_bucket=demographic.age_bucket,
                    gender=demographic.gender,
                    ethnicity=demographic.ethnicity,
                    about=behavioral_content.about,
                    goalsAndMotivations=behavioral_content.goalsAndMotivations,
                    frustrations=behavioral_content.frustrations,
                    needState=behavioral_content.needState,
                    occasions=behavioral_content.occasions,
                    profile_id=i + 1,
                )

                completed_profiles.append(profile)

            except Exception as e:
                logger.error(f"Failed to generate profile {i + 1}: {str(e)}")
                raise

        # Save output
        output_data = {
            "synthetic_audience": [profile.dict() for profile in completed_profiles],
            "generation_metadata": {
                "total_profiles": len(completed_profiles),
                "input_file": input_file,
                "generation_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "distribution_accuracy": self._validate_distribution(
                    completed_profiles, filter_details
                ),
            },
        }

        with open(output_file, "w") as f:
            json.dump(output_data, f, indent=2)

        logger.info(
            f"Generated {len(completed_profiles)} profiles saved to {output_file}"
        )

        return output_data["generation_metadata"]

    def _validate_distribution(
        self, profiles: List[SyntheticProfile], filter_details: FilterDetails
    ) -> Dict[str, Any]:
        """Validate that the generated profiles match the required distribution."""
        total_profiles = len(profiles)

        # Count actual distributions
        gender_counts = {}
        age_counts = {}
        ethnicity_counts = {}

        for profile in profiles:
            # Gender
            gender_counts[profile.gender] = gender_counts.get(profile.gender, 0) + 1
            # Age
            age_counts[profile.age_bucket] = age_counts.get(profile.age_bucket, 0) + 1
            # Ethnicity
            ethnicity_counts[profile.ethnicity] = (
                ethnicity_counts.get(profile.ethnicity, 0) + 1
            )

        # Calculate actual percentages
        gender_percentages = {
            k: round((v / total_profiles) * 100, 1) for k, v in gender_counts.items()
        }
        age_percentages = {
            k: round((v / total_profiles) * 100, 1) for k, v in age_counts.items()
        }
        ethnicity_percentages = {
            k: round((v / total_profiles) * 100, 1) for k, v in ethnicity_counts.items()
        }

        return {
            "total_profiles": total_profiles,
            "expected_total": filter_details.user_req_responses,
            "gender_distribution": {
                "expected": filter_details.gender_proportions,
                "actual_counts": gender_counts,
                "actual_percentages": gender_percentages,
            },
            "age_distribution": {
                "expected": filter_details.age_proportions,
                "actual_counts": age_counts,
                "actual_percentages": age_percentages,
            },
            "ethnicity_distribution": {
                "expected": filter_details.ethnicity_proportions,
                "actual_counts": ethnicity_counts,
                "actual_percentages": ethnicity_percentages,
            },
        }


# ============================================================================
# CLI INTERFACE
# ============================================================================


@click.command()
@click.option("--input", "-i", required=True, help="Input JSON file path")
@click.option("--output", "-o", required=True, help="Output JSON file path")
@click.option(
    "--validate-env", is_flag=True, help="Run environment validation before processing"
)
def main(input: str, output: str, validate_env: bool):
    """Synthetic Audience Generator MVP - Generate synthetic audience profiles."""

    if validate_env:
        logger.info("Running environment validation...")
        os.system("python validate_environment.py")

    try:
        generator = SyntheticAudienceGenerator()
        metadata = generator.process_request(input, output)

        print("\n" + "=" * 60)
        print("✅ GENERATION COMPLETED SUCCESSFULLY")
        print("=" * 60)
        print(f"Total Profiles Generated: {metadata['total_profiles']}")
        print(f"Expected Total: {metadata['distribution_accuracy']['expected_total']}")
        print(f"Output File: {output}")
        print(f"Generation Time: {metadata['generation_timestamp']}")

        # Print distribution summary
        print("\nDistribution Accuracy:")
        print(
            f"Gender: {metadata['distribution_accuracy']['gender_distribution']['actual_percentages']}"
        )
        print(
            f"Age: {metadata['distribution_accuracy']['age_distribution']['actual_percentages']}"
        )
        print(
            f"Ethnicity: {metadata['distribution_accuracy']['ethnicity_distribution']['actual_percentages']}"
        )

    except Exception as e:
        logger.error(f"Generation failed: {str(e)}")
        print(f"\n❌ GENERATION FAILED: {str(e)}")
        exit(1)


if __name__ == "__main__":
    main()
